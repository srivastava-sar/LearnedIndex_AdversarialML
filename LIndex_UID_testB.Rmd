---
title: "Learned Index Structure Dataset AMZ2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DescTools)
```

## R Markdown

```{r echo=FALSE}
knitr::read_chunk('HelperFunction_LIndex.R')
```

Reading the data and then drawing the plot

```{r readData}
DIGIX <- read.csv(file = "datasets/test_data_B-uid.csv")
str(DIGIX)
attach(DIGIX)
```


```{r fitPolynomial, echo=TRUE, eval=FALSE}
<<Polyfit_uid>>
func_fitPoly_uid(X,DIGIX)
```

Based on the fitting, degree 2 polynomial seems suiitable

```{r PolyVisual, echo=TRUE}
<<Polyfit_Visual>>
Quadfunct = func_PolyVis(X,4,uid,DIGIX)
```

### Step 2: Residual visualization
```{r ResidualVisual}

plot(Quadfunct$residuals^2)
ultraMax <- which.max(Quadfunct$residuals^2)
print(Quadfunct$residuals[ultraMax]^2)

# lastN=41 , Res=97000, gives 33 out of 76
maxQ <- which(Quadfunct$residuals^2>30000)
#Max k residuals
#print(maxQ)
#print(maxQ)
print(length(maxQ))
points(maxQ,Quadfunct$residuals[maxQ]^2, col="green",cex=2,pch=20)
```


### Step 3: Raw data analysis without using the model

```{r keydiffVisual}
<<key_diff_visual>>
  keyDiff <- func_keyDiff(X,uid)
  keyDim <- dim(keyDiff)[1]
```

### Step 4: Fitting normal distribution on KeyDiff
CUSUM algorithm is based on the assumption that the underlying algorithm follows a normal distribution. We thus fit a Gaussian curve on the keyDiff data.

```{r GausFit}
<<GaussFit>>
  FIT <- func_FitNorm(keyDiff)
```


### STEP 5: CUSUM implementation
```{r CUSUMCall,eval=TRUE}
<<CUSUM_Impl2>>
  #Orignal threshold=5 works well
outcomeExits = func_CUSUM2(FIT,5,keyDiff,keyDim,y_lim=50)
#print(outcomeExits)
<<PlotRes>>
  func_plotRes(Quadfunct,maxQ,ultraMax)

```


### Step 6: Evaluation 1
```{r evaluation1, eval=TRUE}
<<Evaluation1>>
lastN=50
EvalMeasure = func_eval1(lastN,keyDim,Quadfunct,maxQ,outcomeExits)
print(EvalMeasure)
```
Proportion of relevant points extracted (TODO) 


#### Step 6: Evaluation 2
```{r evaluation2, eval=TRUE}

<<Evaluation2>>
EvalMeasure2 = func_eval2(outcomeExits,keyDim,lastN)

```

Ratio of points visited

### Step 7 : Two sides CUSUM and Evaluation
```{r CUSUMCall_bothDir}

<<CUSUM_Impl3>>
<<CUSUM_Wrapper>>

outcomeExits = func_CUSUM_wrapper(FIT,3.5,keyDiff,keyDim,y_lim=50)

#print(outcomeExits)
func_plotRes(Quadfunct,maxQ,ultraMax)

# lastN=20/3 -> in 71$ walk -> 62% got
# lastN=25/3.5 -> is 70% walk -> 73% got
lastN=25
EvalMeasure = func_eval1(lastN,keyDim,Quadfunct,maxQ,outcomeExits)
print(EvalMeasure)

EvalMeasure2 = func_eval2(outcomeExits,keyDim,lastN)


```


### 8 Grid Search
```{r GridSearch,warning=FALSE}

lastN = seq(10,100,by = 10)
T_factor = seq(3,7,by = 0.5)
eval1 = data.frame(matrix(1:90,ncol=9))
eval2 = data.frame(matrix(1:90,ncol=9))

for (l in 1:10){
  for (t in 1:9){
    outcomeExits = func_CUSUM_wrapper(FIT,T_factor[t],keyDiff,keyDim,y_lim=50,FALSE)
    eval1[l,t] = func_eval1(lastN[l],keyDim,Quadfunct,maxQ,outcomeExits,FALSE)
    eval2[l,t] = func_eval2(outcomeExits,keyDim,lastN[l])
  }
}

names(eval1) <- T_factor
names(eval2) <- T_factor
row.names(eval1) <- lastN
row.names(eval2) <- lastN

print(eval1)
print(eval2)

matplot(eval1,type = "l")
matplot(eval2,type = "l")

detach(DIGIX)

```



